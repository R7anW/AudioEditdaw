<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Audio Studio Pro</title>
  <style>
    body {
      font-family: 'Inter', sans-serif;
      background: linear-gradient(135deg, #0f2027, #203a43, #2c5364);
      color: white;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: flex-start;
      min-height: 100vh;
      margin: 0;
      padding: 20px 15px 40px;
      text-align: center;
    }

    h1 {
      margin-bottom: 0.6em;
      font-weight: 600;
    }

    .controls {
      background: rgba(255, 255, 255, 0.08);
      padding: 25px 25px 30px;
      border-radius: 15px;
      width: 100%;
      max-width: 650px;
      box-shadow: 0 4px 20px rgba(0, 0, 0, 0.4);
      box-sizing: border-box;
    }

    button, select, .upload-btn {
      background: #1e3c72;
      border: none;
      color: white;
      padding: 10px 20px;
      border-radius: 5px;
      cursor: pointer;
      font-size: 1em;
      margin: 10px 8px 10px 0;
      transition: all 0.25s ease;
      user-select: none;
      vertical-align: middle;
    }

    button:hover, select:hover, .upload-btn:hover {
      background: #2a5298;
      transform: translateY(-2px);
    }

    select {
      min-width: 200px;
    }
    input[type="file"] {
      display: none;
    }
    .upload-btn {
      background: #1e3c72;
      display: inline-block;
      margin-bottom: 20px;
    }

    input[type="range"] {
      width: 180px;
      accent-color: #2a5298;
      vertical-align: middle;
    }

    label {
      display: inline-flex;
      align-items: center;
      gap: 10px;
      margin: 8px 12px 8px 0;
      font-size: 0.9em;
      user-select: none;
    }

    /* Hide native audio controls */
    audio {
      display: none;
    }

    canvas#wave {
      width: 100%;
      height: 100px;
      margin-top: 15px;
      background: rgba(0, 0, 0, 0.25);
      border-radius: 8px;
      display: block;
    }

    .meter {
      width: 100%;
      height: 8px;
      border-radius: 4px;
      background: rgba(255,255,255,0.15);
      margin-top: 8px;
      overflow: hidden;
    }

    .meter-fill {
      height: 100%;
      background: #00ffb3;
      width: 0%;
      transition: width 0.1s linear;
    }

    /* Custom audio player container */
    #custom-controls {
      width: 100%;
      max-width: 650px;
      margin-top: 25px;
      background: #222;
      border-radius: 10px;
      padding: 10px 15px;
      display: flex;
      align-items: center;
      gap: 12px;
      color: #1e3c72;
      font-family: 'Inter', sans-serif;
      user-select: none;
      box-sizing: border-box;
    }

    /* Buttons styling */
    #custom-controls button {
      background: none;
      border: none;
      color: #1e3c72;
      font-size: 18px;
      cursor: pointer;
      padding: 0;
      display: flex;
      align-items: center;
      justify-content: center;
      transition: color 0.2s ease;
    }
    #custom-controls button:hover {
      color: #2a5298;
    }

    /* Time display */
    #time {
      min-width: 75px;
      font-size: 14px;
      font-variant-numeric: tabular-nums;
      user-select: none;
    }

    /* Progress bar container */
    #progressContainer {
      flex-grow: 1;
      height: 8px;
      background: #111;
      border-radius: 4px;
      cursor: pointer;
      position: relative;
      overflow: hidden;
    }

    /* Progress bar fill */
    #progressBar {
      height: 8px;
      width: 0%;
      background: #1e3c72;
      border-radius: 4px;
      transition: width 0.1s linear;
    }

    /* Volume slider style */
    #volumeSlider {
      width: 100px;
      cursor: pointer;
      accent-color: #1e3c72;
    }

    /* Audio visualizer canvas */
    #audioVisualizer {
      background: #111;
      border-radius: 10px;
      margin-top: 20px;
      width: 100%;
      height: 70px;
      display: block;
      box-sizing: border-box;
    }

    /* Responsive tweaks */
    @media (max-width: 480px) {
      button, select, .upload-btn, label input[type="range"] {
        width: 100%;
        margin: 10px 0 10px 0;
      }
      label {
        display: block;
        margin-bottom: 10px;
      }
      #custom-controls {
        flex-wrap: wrap;
        gap: 10px;
      }
      #volumeSlider {
        width: 100%;
      }
    }
  </style>
</head>
<body>
  <h1>üéß Audio Studio Pro</h1>
  <div class="controls">
    <label class="upload-btn" for="audioFile">üìÅ Upload Audio</label>
    <input type="file" id="audioFile" accept="audio/*" /><br />

    <label for="micSelect">üéôÔ∏è Microphone:</label>
    <select id="micSelect"></select><br />

    <button id="recordBtn">üéôÔ∏è Record</button>
    <button id="stopBtn" disabled>‚èπÔ∏è Stop</button>

    <div class="effect-row" style="margin-top: 10px; display: flex; flex-wrap: wrap; justify-content: center;">
      <label>Reverb: <input type="range" id="reverb" min="0" max="1" step="0.01" value="0" /></label>
      <label>Gain: <input type="range" id="gain" min="0" max="2" step="0.01" value="1" /></label>
      <label>Speed: <input type="range" id="speed" min="0.5" max="2" step="0.01" value="1" /></label>
    </div>

    <button id="playBtn" disabled style="margin-top: 15px;">‚ñ∂Ô∏è Play</button>
    <button id="exportBtn" disabled>üíæ Export WAV</button>

    <canvas id="wave"></canvas>
    <div class="meter"><div class="meter-fill" id="meterFill"></div></div>

    <!-- Hidden native audio element -->
    <audio id="player" preload="metadata"></audio>

    <!-- Audio waveform visualizer canvas -->
    <canvas id="audioVisualizer"></canvas>
  </div>

  <!-- Custom audio player -->
  <div id="custom-controls">
    <button id="playPause">‚ñ∂Ô∏è</button>
    <div id="time">0:00 / 0:00</div>
    <div id="progressContainer">
      <div id="progressBar"></div>
    </div>
    <input type="range" id="volumeSlider" min="0" max="1" step="0.01" value="1" />
  </div>

  <script>
    const fileInput = document.getElementById('audioFile');
    const recordBtn = document.getElementById('recordBtn');
    const stopBtn = document.getElementById('stopBtn');
    const playBtn = document.getElementById('playBtn');
    const exportBtn = document.getElementById('exportBtn');
    const micSelect = document.getElementById('micSelect');
    const reverbControl = document.getElementById('reverb');
    const gainControl = document.getElementById('gain');
    const speedControl = document.getElementById('speed');
    const player = document.getElementById('player');
    const waveCanvas = document.getElementById('wave');
    const meterFill = document.getElementById('meterFill');

    // Custom player controls
    const playPause = document.getElementById('playPause');
    const timeDisplay = document.getElementById('time');
    const progressContainer = document.getElementById('progressContainer');
    const progressBar = document.getElementById('progressBar');
    const volumeSlider = document.getElementById('volumeSlider');

    // Visualizer canvas & context
    const audioVisualizer = document.getElementById('audioVisualizer');
    const visualCtx = audioVisualizer.getContext('2d');

    let audioCtx, buffer, mediaRecorder, recordedChunks = [];
    let currentStream = null, analyser, source, animationId;

    // Initialize AudioContext on user interaction (to avoid autoplay block)
    function initAudioCtx() {
      if (!audioCtx) audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    }

    async function loadMicrophones() {
      try {
        const devices = await navigator.mediaDevices.enumerateDevices();
        const mics = devices.filter(d => d.kind === 'audioinput');
        micSelect.innerHTML = '';
        mics.forEach((mic, i) => {
          const option = document.createElement('option');
          option.value = mic.deviceId;
          option.textContent = mic.label || `Microphone ${i + 1}`;
          micSelect.appendChild(option);
        });
      } catch (err) {
        console.error('Could not enumerate devices:', err);
      }
    }

    // Load microphones on page load
    navigator.mediaDevices.getUserMedia({ audio: true })
      .then(loadMicrophones)
      .catch(console.error);

    // Load audio file
    fileInput.addEventListener('change', async (e) => {
      const file = e.target.files[0];
      if (!file) return;
      initAudioCtx();
      const arrayBuffer = await file.arrayBuffer();
      buffer = await audioCtx.decodeAudioData(arrayBuffer);
      playBtn.disabled = false;
      exportBtn.disabled = false;

      // Load file to audio element for playback and custom player
      player.src = URL.createObjectURL(file);
    });

    // Record button clicked
    recordBtn.addEventListener('click', async () => {
      initAudioCtx();
      const deviceId = micSelect.value;
      const constraints = { audio: { deviceId: deviceId ? { exact: deviceId } : undefined } };

      if (currentStream) currentStream.getTracks().forEach(track => track.stop());
      currentStream = await navigator.mediaDevices.getUserMedia(constraints);
      mediaRecorder = new MediaRecorder(currentStream);
      recordedChunks = [];

      const micSource = audioCtx.createMediaStreamSource(currentStream);
      analyser = audioCtx.createAnalyser();
      analyser.fftSize = 2048;
      micSource.connect(analyser);

      visualizeWaveform(analyser);

      mediaRecorder.ondataavailable = e => recordedChunks.push(e.data);
      mediaRecorder.onstop = () => {
        const blob = new Blob(recordedChunks, { type: 'audio/webm' });
        player.src = URL.createObjectURL(blob);
        exportBtn.disabled = false;
        cancelAnimationFrame(animationId);
        meterFill.style.width = '0%';
      };

      mediaRecorder.start();
      recordBtn.classList.add('recording');
      recordBtn.textContent = 'üî¥ Recording...';
      recordBtn.disabled = true;
      stopBtn.disabled = false;
    });

    // Stop recording
    stopBtn.addEventListener('click', () => {
      if (mediaRecorder && mediaRecorder.state === 'recording') mediaRecorder.stop();
      recordBtn.classList.remove('recording');
      recordBtn.textContent = 'üéôÔ∏è Record';
      recordBtn.disabled = false;
      stopBtn.disabled = true;
    });

    // Play button clicked: playback buffer with effects
    playBtn.addEventListener('click', () => {
      if (!buffer) return;
      initAudioCtx();

      if (source) source.stop(); // stop overlapping playback

      source = audioCtx.createBufferSource();
      source.buffer = buffer;
      source.playbackRate.value = parseFloat(speedControl.value);

      const gainNode = audioCtx.createGain();
      gainNode.gain.value = parseFloat(gainControl.value);

      const convolver = audioCtx.createConvolver();
      const reverbAmount = parseFloat(reverbControl.value);
      const impulse = audioCtx.createBuffer(2, audioCtx.sampleRate * 3, audioCtx.sampleRate);
      for (let i = 0; i < impulse.length; i++) {
        impulse.getChannelData(0)[i] = (Math.random() * 2 - 1) * reverbAmount;
        impulse.getChannelData(1)[i] = (Math.random() * 2 - 1) * reverbAmount;
      }
      convolver.buffer = impulse;

      analyser = audioCtx.createAnalyser();
      analyser.fftSize = 2048;

      source.connect(convolver);
      convolver.connect(gainNode);
      gainNode.connect(analyser);
      analyser.connect(audioCtx.destination);

      visualizeWaveform(analyser);
      source.start();
    });

    // Visualize waveform (time-domain data)
    function visualizeWaveform(analyser) {
      const ctx = waveCanvas.getContext('2d');
      const bufferLength = analyser.fftSize;
      const dataArray = new Uint8Array(bufferLength);

      function draw() {
        animationId = requestAnimationFrame(draw);
        analyser.getByteTimeDomainData(dataArray);

        ctx.fillStyle = 'rgba(0,0,0,0.3)';
        ctx.fillRect(0, 0, waveCanvas.width, waveCanvas.height);

        ctx.lineWidth = 2;
        ctx.strokeStyle = '#00ffb3';
        ctx.beginPath();

        const sliceWidth = waveCanvas.width / bufferLength;
        let x = 0;
        let sum = 0;

        for (let i = 0; i < bufferLength; i++) {
          const v = dataArray[i] / 128.0; // normalized [0, 2]
          const y = v * waveCanvas.height / 2;
          if (i === 0) ctx.moveTo(x, y);
          else ctx.lineTo(x, y);
          x += sliceWidth;
          sum += Math.abs(v - 1);
        }

        ctx.stroke();

        const level = Math.min(100, (sum / bufferLength) * 200);
        meterFill.style.width = level + '%';
      }

      draw();
    }

    // Export WAV (downloads current audio element source)
    exportBtn.addEventListener('click', async () => {
      const response = await fetch(player.src);
      const blob = await response.blob();
      const a = document.createElement('a');
      a.href = URL.createObjectURL(blob);
      a.download = 'edited_audio.wav';
      a.click();
    });

    // ======= Custom audio player logic =======

    // Play/pause toggle
    playPause.addEventListener('click', () => {
      if (player.paused) player.play();
      else player.pause();
    });

    player.addEventListener('play', () => {
      playPause.textContent = '‚è∏Ô∏è';
    });

    player.addEventListener('pause', () => {
      playPause.textContent = '‚ñ∂Ô∏è';
    });

    // Update time and progress bar
    player.addEventListener('timeupdate', () => {
      const current = player.currentTime;
      const duration = player.duration || 0;
      const percent = (current / duration) * 100;
      progressBar.style.width = percent + '%';

      function formatTime(t) {
        const m = Math.floor(t / 60);
        const s = Math.floor(t % 60);
        return m + ':' + (s < 10 ? '0' + s : s);
      }
      timeDisplay.textContent = `${formatTime(current)} / ${formatTime(duration)}`;
    });

    // Scrub on progress bar click
    progressContainer.addEventListener('click', e => {
      const rect = progressContainer.getBoundingClientRect();
      const clickX = e.clientX - rect.left;
      const width = rect.width;
      const newTime = (clickX / width) * player.duration;
      player.currentTime = newTime;
    });

    // Volume slider control
    volumeSlider.addEventListener('input', () => {
      player.volume = volumeSlider.value;
      if (player.volume === 0) {
        volumeSlider.style.accentColor = '#ff4d4d'; // red tint when muted
      } else {
        volumeSlider.style.accentColor = '#1e3c72'; // normal blue tint
      }
    });

    // ======== Audio Waveform Visualizer for custom player ========

    // Setup audio context and analyser for visualizer linked to player element
    function setupVisualizer() {
      if (!audioCtx) audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      if (!source) source = audioCtx.createMediaElementSource(player);

      if (!analyser) {
        analyser = audioCtx.createAnalyser();
        analyser.fftSize = 2048;
        source.connect(analyser);
        analyser.connect(audioCtx.destination);
      }
      visualizeAudioWaveform();
    }

    // Visualize waveform (time domain) on #audioVisualizer canvas
    function visualizeAudioWaveform() {
      const bufferLength = analyser.fftSize;
      const dataArray = new Uint8Array(bufferLength);

      function draw() {
        requestAnimationFrame(draw);

        analyser.getByteTimeDomainData(dataArray);

        visualCtx.fillStyle = '#111';
        visualCtx.fillRect(0, 0, audioVisualizer.width, audioVisualizer.height);

        visualCtx.lineWidth = 2;
        visualCtx.strokeStyle = '#1e3c72';
        visualCtx.beginPath();

        const sliceWidth = audioVisualizer.width / bufferLength;
        let x = 0;

        for (let i = 0; i < bufferLength; i++) {
          const v = dataArray[i] / 128.0;
          const y = v * audioVisualizer.height / 2;
          if (i === 0) visualCtx.moveTo(x, y);
          else visualCtx.lineTo(x, y);
          x += sliceWidth;
        }

        visualCtx.lineTo(audioVisualizer.width, audioVisualizer.height / 2);
        visualCtx.stroke();
      }

      draw();
    }

    // Resize canvases to fit container width for high-DPI screens
    function resizeCanvases() {
      // wave canvas
      waveCanvas.width = waveCanvas.clientWidth * devicePixelRatio;
      waveCanvas.height = waveCanvas.clientHeight * devicePixelRatio;
      waveCanvas.getContext('2d').scale(devicePixelRatio, devicePixelRatio);

      // audioVisualizer canvas
      audioVisualizer.width = audioVisualizer.clientWidth * devicePixelRatio;
      audioVisualizer.height = audioVisualizer.clientHeight * devicePixelRatio;
      visualCtx.scale(devicePixelRatio, devicePixelRatio);
    }

    window.addEventListener('resize', () => {
      resizeCanvases();
    });

    // Initial resize on page load
    resizeCanvases();

    // Setup visualizer for audio element when metadata loaded
    player.addEventListener('loadedmetadata', () => {
      setupVisualizer();
    });
  </script>
</body>
</html>
